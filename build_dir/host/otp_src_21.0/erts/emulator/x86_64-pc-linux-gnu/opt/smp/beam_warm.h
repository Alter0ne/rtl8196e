/*
 *  Warning: Do not edit this file.
 *  Auto-generated by 'beam_makeops'.
 */

OpCase(bs_add_jsstx):
{
  Eterm tmp_packed1 = I[4];
  Eterm targ1;
  Eterm targ2;
  GetR(1, targ1);
  GetR(2, targ2);
  {
    Eterm Op1 = targ1;
    Eterm Op2 = targ2;
    Uint unit = tb(tmp_packed1&BEAM_LOOSE_MASK);

    if (is_both_small(Op1, Op2)) {
      Sint Arg1 = signed_val(Op1);
      Sint Arg2 = signed_val(Op2);

      if (Arg1 >= 0 && Arg2 >= 0) {
        do {
          Uint64 res = (Arg2) * (unit);
          if (res / unit != Arg2) {
            c_p->freason = SYSTEM_LIMIT;

            /*
            * In a correctly working program, we expect failures in
            * guards to be more likely than failures in bodies.
            */

            if (ERTS_LIKELY(I[1])) {
              ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
              I += I[1] + 0;;
              Goto(*I);;
            }
            goto find_func_info;;;
          }
          Op1 = res;
        } while (0);
        Op1 += Arg1;

        store_bs_add_result:
        if (Op1 <= MAX_SMALL) {
          Op1 = make_small(Op1);
        } else {
          /*
          * May generate a heap fragment, but in this
          * particular case it is OK, since the value will be
          * stored into an x register (the GC will scan x
          * registers for references to heap fragments) and
          * there is no risk that value can be stored into a
          * location that is not scanned for heap-fragment
          * references (such as the heap).
          */
          SWAPOUT;
          Op1 = erts_make_integer(Op1, c_p);
          HTOP = HEAP_TOP(c_p);
        }
        xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = Op1;
        SET_I((BeamInstr *) I+5);
        Goto(*I);;
      }
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(I[1])) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    } else {
      Uint a;
      Uint b;
      Uint c;

      /*
      * Now we know that one of the arguments is
      * not a small. We must convert both arguments
      * to Uints and check for errors at the same time.
      *
      * Error checking is tricky.
      *
      * If one of the arguments is not numeric or
      * not positive, the error reason is BADARG.
      *
      * Otherwise if both arguments are numeric,
      * but at least one argument does not fit in
      * an Uint, the reason is SYSTEM_LIMIT.
      */

      if (!term_to_Uint(Op1, &a)) {
        if (a == BADARG) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(I[1])) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        if (!term_to_Uint(Op2, &b)) {
          c_p->freason = b;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(I[1])) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
          goto find_func_info;;
        }
        c_p->freason = SYSTEM_LIMIT;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      } else if (!term_to_Uint(Op2, &b)) {
        c_p->freason = b;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;
      }

      /*
      * The arguments are now correct and stored in a and b.
      */

      do {
        Uint64 res = (b) * (unit);
        if (res / unit != b) {
          c_p->freason = SYSTEM_LIMIT;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(I[1])) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        c = res;
      } while (0);
      Op1 = a + c;
      if (Op1 < a) {
        /*
        * If the result is less than one of the
        * arguments, there must have been an overflow.
        */
        c_p->freason = SYSTEM_LIMIT;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      goto store_bs_add_result;
    }
    /* No fallthrough */
    ASSERT(0);
  }
}

{
  Eterm context;
  ErlBinMatchBuffer* mb;
  Uint size;
  Uint offs;
  OpCase(bs_context_to_binary_x):
  {
    context = xb(I[1]);
    if (is_boxed(context) &&
    header_is_bin_matchstate(*boxed_val(context))) {
      ErlBinMatchState* ms;
      ms = (ErlBinMatchState *) boxed_val(context);
      mb = &ms->mb;
      offs = ms->save_offset[0];
      size = mb->size - offs;
    } else {
      SET_I((BeamInstr *) I+2);
      Goto(*I);;
    }
  }
  goto ctx_to_bin__execute;

  OpCase(i_bs_get_binary_all_reuse_xft):
  {
    Eterm tmp_packed1 = I[1];
    context = xb(tmp_packed1&BEAM_LOOSE_MASK);
    mb = ms_matchbuffer(context);
    size = mb->size - mb->offset;
    if (size % tb((tmp_packed1>>BEAM_LOOSE_SHIFT)) != 0) {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 1)));
      I += I[2] + 1;;
      Goto(*I);;
    }
    offs = mb->offset;
  }
  I += 1;
  goto ctx_to_bin__execute;

  ctx_to_bin__execute:
  {
    BeamInstr next_pf = BeamCodeAddr(I[2]);
    Uint hole_size;
    Uint orig = mb->orig;
    ErlSubBin* sb = (ErlSubBin *) boxed_val(context);
    /* Since we're going to overwrite the match state with the result, an
    * ErlBinMatchState must be at least as large as an ErlSubBin. */
    ERTS_CT_ASSERT(sizeof(ErlSubBin) <= sizeof(ErlBinMatchState));
    hole_size = 1 + header_arity(sb->thing_word) - ERL_SUB_BIN_SIZE;
    sb->thing_word = HEADER_SUB_BIN;
    sb->size = BYTE_OFFSET(size);
    sb->bitsize = BIT_OFFSET(size);
    sb->offs = BYTE_OFFSET(offs);
    sb->bitoffs = BIT_OFFSET(offs);
    sb->is_writable = 0;
    sb->orig = orig;
    if (hole_size) {
      sb[1].thing_word = make_pos_bignum_header(hole_size-1);
    }
    I += 2;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

OpCase(bs_init_writable):
{
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  HEAVY_SWAPOUT;
  r(0) = erts_bs_init_writable(c_p, r(0));
  HEAVY_SWAPIN;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_put_string_WW):
{
  BeamInstr next_pf = BeamCodeAddr(I[3]);
  erts_new_bs_put_string(ERL_BITS_ARGS_2((byte *) I[2], I[1]));
  I += 3;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_put_utf16_jts):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  GetR(1, targ1);
  {
    if (!erts_bs_put_utf16(ERL_BITS_ARGS_2(targ1, tb((tmp_packed1>>BEAM_WIDE_SHIFT))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(bs_test_tail_imm2_fxW):
{
  Eterm tmp_packed1 = I[1];
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb((tmp_packed1>>BEAM_WIDE_SHIFT)));
  if (_mb->size - _mb->offset != I[2]) {
    ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
    I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_unit8_fx):
{
  Eterm tmp_packed1 = I[1];
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb((tmp_packed1>>BEAM_WIDE_SHIFT)));
  if ((_mb->size - _mb->offset) & 7) {
    ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
    I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_unit_fxt):
{
  Eterm tmp_packed1 = I[2];
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));
  if ((_mb->size - _mb->offset) % tb((tmp_packed1>>BEAM_LOOSE_SHIFT))) {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_zero_tail2_fx):
{
  Eterm tmp_packed1 = I[1];
  ErlBinMatchBuffer *_mb;
  _mb = (ErlBinMatchBuffer*) ms_matchbuffer(xb((tmp_packed1>>BEAM_WIDE_SHIFT)));
  if (_mb->size != _mb->offset) {
    ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
    I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(fconv_Sl):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  Eterm src = Sb(tmp_packed1&BEAM_LOOSE_MASK);

  if (is_small(src)) {
    lb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = (double) signed_val(src);
  } else if (is_big(src)) {
    if (big_to_double(src, &lb((tmp_packed1>>BEAM_LOOSE_SHIFT))) < 0) {
      c_p->freason = BADARITH;
      goto find_func_info;;
    }
  } else if (is_float(src)) {
    do {
      GET_DOUBLE(src, *(FloatDef *) &lb((tmp_packed1>>BEAM_LOOSE_SHIFT)));
    } while (0);
  } else {
    c_p->freason = BADARITH;
    goto find_func_info;;
  }
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(fload_Sl):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  do {
    GET_DOUBLE(Sb(tmp_packed1&BEAM_LOOSE_MASK), *(FloatDef *) &lb((tmp_packed1>>BEAM_LOOSE_SHIFT)));
  } while (0);
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(fload_ql):
{
  BeamInstr next_pf = BeamCodeAddr(I[3]);
  do {
    GET_DOUBLE(I[1], *(FloatDef *) &lb(I[2]));
  } while (0);
  I += 3;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(fstore_ld):
{
  Eterm tmp_packed1 = I[1];
  Eterm dst = db((tmp_packed1>>BEAM_LOOSE_SHIFT));
  Eterm* dst_ptr = REG_TARGET_PTR(dst);
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  PUT_DOUBLE(*((FloatDef *) &lb(tmp_packed1&BEAM_LOOSE_MASK)), HTOP);
  *dst_ptr = make_float(HTOP);
  HTOP += FLOAT_SIZE_OBJECT;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_append_jIttsx):
{
  Eterm tmp_packed1 = I[1];
  Eterm tmp_packed2 = I[2];
  Eterm targ1;
  GetR(2, targ1);
  {
    Uint live = tb(tmp_packed2&BEAM_TIGHT_MASK);
    Uint res;

    HEAVY_SWAPOUT;
    reg[live] = x(SCRATCH_X_REG);
    res = erts_bs_append(c_p, reg, live, targ1, Ib((tmp_packed1>>BEAM_WIDE_SHIFT)), tb((tmp_packed2>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK));
    HEAVY_SWAPIN;
    if (is_non_value(res)) {
      /* c_p->freason is already set (to BADARG or SYSTEM_LIMIT). */

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;
    }
    xb((tmp_packed2>>(2*BEAM_TIGHT_SHIFT))) = res;
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_get_binary2_fxtstx):
{
  Eterm tmp_packed1 = I[2];
  Eterm targ1;
  GetR(2, targ1);
  {
    ErlBinMatchBuffer *_mb;
    Eterm _result;
    Uint _size;
    do {
      Sint signed_size;
      Uint uint_size;
      Uint temp_bits;

      if (is_small(targ1)) {
        signed_size = signed_val(targ1);
        if (signed_size < 0) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        uint_size = (Uint) signed_size;
      } else {
        if (!term_to_Uint(targ1, &temp_bits)) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        uint_size = temp_bits;
      }
      do {
        Uint64 res = (uint_size) * (((tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK)) >> 3));
        if (res / ((tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK)) >> 3) != uint_size) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        _size = res;
      } while (0);
    } while (0);
    do {
      Uint need = ERL_SUB_BIN_SIZE + 0;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        SWAPOUT;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_LOOSE_SHIFT)&BEAM_LOOSE_MASK), FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(ERL_SUB_BIN_SIZE);
    } while (0);
    _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));
    LIGHT_SWAPOUT;
    _result = erts_bs_get_binary_2(c_p, _size, tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK), _mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    if (is_non_value(_result)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    } else {
      xb((tmp_packed1>>(3*BEAM_LOOSE_SHIFT))) = _result;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_get_binary_all2_fxttx):
{
  Eterm tmp_packed1 = I[2];
  ErlBinMatchBuffer *_mb;
  Eterm _result;

  do {
    Uint need = ERL_SUB_BIN_SIZE + 0;
    if (ERTS_UNLIKELY(E - HTOP < need)) {
      SWAPOUT;
      PROCESS_MAIN_CHK_LOCKS(c_p);
      FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_LOOSE_SHIFT)&BEAM_LOOSE_MASK), FCALLS);
      ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
      PROCESS_MAIN_CHK_LOCKS(c_p);
      SWAPIN;
    }
    HEAP_SPACE_VERIFIED(ERL_SUB_BIN_SIZE);
  } while (0);
  _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));
  if (((_mb->size - _mb->offset) % tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK)) == 0) {
    LIGHT_SWAPOUT;
    _result = erts_bs_get_binary_all_2(c_p, _mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    ASSERT(is_value(_result));
    xb((tmp_packed1>>(3*BEAM_LOOSE_SHIFT))) = _result;
  } else {
    HEAP_SPACE_VERIFIED(0);
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_get_binary_imm2_fxtWtx):
{
  Eterm tmp_packed1 = I[2];
  ErlBinMatchBuffer *_mb;
  Eterm _result;
  do {
    Uint need = heap_bin_size(ERL_ONHEAP_BIN_LIMIT) + 0;
    if (ERTS_UNLIKELY(E - HTOP < need)) {
      SWAPOUT;
      PROCESS_MAIN_CHK_LOCKS(c_p);
      FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_LOOSE_SHIFT)&BEAM_LOOSE_MASK), FCALLS);
      ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
      PROCESS_MAIN_CHK_LOCKS(c_p);
      SWAPIN;
    }
    HEAP_SPACE_VERIFIED(heap_bin_size(ERL_ONHEAP_BIN_LIMIT));
  } while (0);
  _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));
  LIGHT_SWAPOUT;
  _result = erts_bs_get_binary_2(c_p, I[3], tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK), _mb);
  LIGHT_SWAPIN;
  HEAP_SPACE_VERIFIED(0);
  if (is_non_value(_result)) {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  } else {
    xb((tmp_packed1>>(3*BEAM_LOOSE_SHIFT))) = _result;
  }
  I += 4;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_get_float2_fxtstx):
{
  Eterm tmp_packed1 = I[2];
  Eterm targ1;
  GetR(2, targ1);
  {
    ErlBinMatchBuffer *_mb;
    Eterm _result;
    Sint _size;

    if (!is_small(targ1) || (_size = unsigned_val(targ1)) > 64) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
    _size *= ((tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK)) >> 3);
    do {
      Uint need = FLOAT_SIZE_OBJECT + 0;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        SWAPOUT;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_LOOSE_SHIFT)&BEAM_LOOSE_MASK), FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(FLOAT_SIZE_OBJECT);
    } while (0);
    _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));
    LIGHT_SWAPOUT;
    _result = erts_bs_get_float_2(c_p, _size, (tb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK)), _mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    if (is_non_value(_result)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    } else {
      xb((tmp_packed1>>(3*BEAM_LOOSE_SHIFT))) = _result;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_get_integer_16_xfx):
{
  Eterm tmp_packed1 = I[1];
  Eterm _result;
  ErlBinMatchBuffer* _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));

  if (_mb->size - _mb->offset < 16) {
    ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
    I += I[2] + 0;;
    Goto(*I);;
  }
  if (BIT_OFFSET(_mb->offset) != 0) {
    _result = erts_bs_get_integer_2(c_p, 16, 0, _mb);
  } else {
    _result = make_small(get_int16(_mb->base+BYTE_OFFSET(_mb->offset)));
    _mb->offset += 16;
  }
  xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = _result;
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_get_integer_32_xfx):
{
  Eterm tmp_packed1 = I[1];
  Uint32 _integer;
  ErlBinMatchBuffer* _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));

  if (_mb->size - _mb->offset < 32) {
    ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
    I += I[2] + 0;;
    Goto(*I);;
  }
  if (BIT_OFFSET(_mb->offset) != 0) {
    _integer = erts_bs_get_unaligned_uint32(_mb);
  } else {
    _integer = get_int32(_mb->base + _mb->offset/8);
  }
  _mb->offset += 32;
  xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = make_small(_integer);
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_get_integer_8_xfx):
{
  Eterm tmp_packed1 = I[1];
  Eterm _result;
  ErlBinMatchBuffer* _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));

  if (_mb->size - _mb->offset < 8) {
    ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
    I += I[2] + 0;;
    Goto(*I);;
  }
  if (BIT_OFFSET(_mb->offset) != 0) {
    _result = erts_bs_get_integer_2(c_p, 8, 0, _mb);
  } else {
    _result = make_small(_mb->base[BYTE_OFFSET(_mb->offset)]);
    _mb->offset += 8;
  }
  xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = _result;
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_get_integer_fttxsx):
{
  Eterm tmp_packed1 = I[2];
  Eterm targ1;
  GetR(2, targ1);
  {
    Uint flags;
    Uint size;
    Eterm ms;
    ErlBinMatchBuffer* mb;
    Eterm result;

    flags = tb((tmp_packed1>>BEAM_LOOSE_SHIFT)&BEAM_LOOSE_MASK);
    ms = xb((tmp_packed1>>(2*BEAM_LOOSE_SHIFT))&BEAM_LOOSE_MASK);
    do {
      Sint signed_size;
      Uint uint_size;
      Uint temp_bits;

      if (is_small(targ1)) {
        signed_size = signed_val(targ1);
        if (signed_size < 0) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        uint_size = (Uint) signed_size;
      } else {
        if (!term_to_Uint(targ1, &temp_bits)) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        uint_size = temp_bits;
      }
      do {
        Uint64 res = (uint_size) * ((flags >> 3));
        if (res / (flags >> 3) != uint_size) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        size = res;
      } while (0);
    } while (0);
    if (size >= SMALL_BITS) {
      Uint wordsneeded;
      /* Check bits size before potential gc.
      * We do not want a gc and then realize we don't need
      * the allocated space (i.e. if the op fails).
      *
      * Remember to re-acquire the matchbuffer after gc.
      */

      mb = ms_matchbuffer(ms);
      if (mb->size - mb->offset < size) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      wordsneeded = 1+WSIZE(NBYTES((Uint) size));
      do {
        Uint need = wordsneeded;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          SWAPOUT;
          reg[tb(tmp_packed1&BEAM_LOOSE_MASK)] = ms;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK)+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          ms = reg[tb(tmp_packed1&BEAM_LOOSE_MASK)];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(wordsneeded);
      } while (0);
    }
    mb = ms_matchbuffer(ms);
    LIGHT_SWAPOUT;
    result = erts_bs_get_integer_2(c_p, size, flags, mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    if (is_non_value(result)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
    xb((tmp_packed1>>(3*BEAM_LOOSE_SHIFT))) = result;
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

{
  Eterm Ms, Sz;
  OpCase(i_bs_get_integer_imm_xWtftx):
  {
    Eterm tmp_packed1 = I[1];
    Uint wordsneeded;
    Ms = xb(tmp_packed1&BEAM_LOOSE_MASK);
    Sz = I[2];
    wordsneeded = 1+WSIZE(NBYTES(Sz));
    do {
      Uint need = wordsneeded;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        SWAPOUT;
        reg[tb((tmp_packed1>>BEAM_LOOSE_SHIFT))] = Ms;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_LOOSE_SHIFT))+1, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        Ms = reg[tb((tmp_packed1>>BEAM_LOOSE_SHIFT))];
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(wordsneeded);
    } while (0);
  }
  goto bs_get_integer__execute;

  OpCase(i_bs_get_integer_small_imm_xWftx):
  {
    Ms = xb(I[1]);
    Sz = I[2];
  }
  goto bs_get_integer__execute;

  bs_get_integer__execute:
  {
    Eterm tmp_packed1 = I[4];
    ErlBinMatchBuffer* mb;
    Eterm result;

    mb = ms_matchbuffer(Ms);
    LIGHT_SWAPOUT;
    result = erts_bs_get_integer_2(c_p, Sz, tb(tmp_packed1&BEAM_LOOSE_MASK), mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    if (is_non_value(result)) {
      ASSERT(VALID_INSTR(*(I + (I[3]) + 0)));
      I += I[3] + 0;;
      Goto(*I);;
    }
    xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = result;
    I += 5;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_bs_get_utf16_xftx):
{
  Eterm tmp_packed1 = I[1];
  ErlBinMatchBuffer* mb = ms_matchbuffer(xb(tmp_packed1&BEAM_TIGHT_MASK));
  Eterm result = erts_bs_get_utf16(mb, tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK));

  if (is_non_value(result)) {
    ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
    I += I[2] + 0;;
    Goto(*I);;
  }
  xb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = result;
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_get_utf8_xfx):
{
  Eterm tmp_packed1 = I[1];
  Eterm result;
  ErlBinMatchBuffer* mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));

  if (mb->size - mb->offset < 8) {
    ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
    I += I[2] + 0;;
    Goto(*I);;
  }
  if (BIT_OFFSET(mb->offset) != 0) {
    result = erts_bs_get_utf8(mb);
  } else {
    byte b = mb->base[BYTE_OFFSET(mb->offset)];
    if (b < 128) {
      result = make_small(b);
      mb->offset += 8;
    } else {
      result = erts_bs_get_utf8(mb);
    }
  }
  if (is_non_value(result)) {
    ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
    I += I[2] + 0;;
    Goto(*I);;
  }
  xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = result;
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

{
  Eterm BsOp1;
  Eterm BsOp2;
  OpCase(i_bs_init_Wtx):
  {
    BsOp1 = I[1];
    BsOp2 = 0;
  }
  goto bs_init__execute;

  OpCase(i_bs_init_fail_heap_sIjtx):
  {
    Eterm targ1;
    GetR(0, targ1);
    {
      BsOp1 = targ1;
      BsOp2 = I[2];
    }
  }
  I += 1;
  goto bs_init__verify;

  OpCase(i_bs_init_fail_xjtx):
  {
    BsOp1 = xb(I[1]);
    BsOp2 = 0;
  }
  goto bs_init__verify;

  OpCase(i_bs_init_fail_yjtx):
  {
    BsOp1 = yb(I[1]);
    BsOp2 = 0;
  }
  goto bs_init__verify;

  OpCase(i_bs_init_heap_WItx):
  {
    BsOp1 = I[1];
    BsOp2 = I[2];
  }
  I += 1;
  goto bs_init__execute;

  bs_init__verify:
  {
    if (is_small(BsOp1)) {
      Sint size = signed_val(BsOp1);
      if (size < 0) {
        c_p->freason = BADARG;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[2])) {
          ASSERT(VALID_INSTR(*(I + (I[2]) + 1)));
          I += I[2] + 1;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      BsOp1 = (Eterm) size;
    } else {
      Uint bytes;

      if (!term_to_Uint(BsOp1, &bytes)) {
        c_p->freason = bytes;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[2])) {
          ASSERT(VALID_INSTR(*(I + (I[2]) + 1)));
          I += I[2] + 1;;
          Goto(*I);;
        }
        goto find_func_info;;
      }
      if ((bytes >> (8*sizeof(Uint)-3)) != 0) {
        c_p->freason = SYSTEM_LIMIT;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[2])) {
          ASSERT(VALID_INSTR(*(I + (I[2]) + 1)));
          I += I[2] + 1;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      BsOp1 = (Eterm) bytes;
    }
  }
  I += 1;
  goto bs_init__execute;

  bs_init__execute:
  {
    Eterm tmp_packed1 = I[2];
    BeamInstr next_pf = BeamCodeAddr(I[3]);
    if (BsOp1 <= ERL_ONHEAP_BIN_LIMIT) {
      ErlHeapBin* hb;
      Uint bin_need;

      bin_need = heap_bin_size(BsOp1);
      erts_bin_offset = 0;
      erts_writable_bin = 0;
      do {
        Uint need = bin_need+BsOp2+ERL_SUB_BIN_SIZE + 0;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          SWAPOUT;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK), FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(bin_need+BsOp2+ERL_SUB_BIN_SIZE);
      } while (0);
      hb = (ErlHeapBin *) HTOP;
      HTOP += bin_need;
      hb->thing_word = header_heap_bin(BsOp1);
      hb->size = BsOp1;
      erts_current_bin = (byte *) hb->data;
      xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = make_binary(hb);
    } else {
      Binary* bptr;
      ProcBin* pb;

      erts_bin_offset = 0;
      erts_writable_bin = 0;
      do {
        Uint need = BsOp2 + PROC_BIN_SIZE + ERL_SUB_BIN_SIZE;
        if (E - HTOP < need || MSO(c_p).overhead + BsOp1 / sizeof(Eterm) >= BIN_VHEAP_SZ(c_p)) {
          SWAPOUT;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK), FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(need);
      } while (0);

      /*
      * Allocate the binary struct itself.
      */
      bptr = erts_bin_nrml_alloc(BsOp1);
      erts_current_bin = (byte *) bptr->orig_bytes;

      /*
      * Now allocate the ProcBin on the heap.
      */
      pb = (ProcBin *) HTOP;
      HTOP += PROC_BIN_SIZE;
      pb->thing_word = HEADER_PROC_BIN;
      pb->size = BsOp1;
      pb->next = MSO(c_p).first;
      MSO(c_p).first = (struct erl_off_heap_header*) pb;
      pb->val = bptr;
      pb->bytes = (byte*) bptr->orig_bytes;
      pb->flags = 0;

      OH_OVERHEAD(&(MSO(c_p)), BsOp1 / sizeof(Eterm));

      xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = make_binary(pb);
    }
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

{
  Eterm num_bits_term;
  Uint num_bits;
  Uint alloc;
  OpCase(i_bs_init_bits_Wtx):
  {
    num_bits = I[1];
    alloc = 0;
  }
  goto bs_init_bits__execute;

  OpCase(i_bs_init_bits_fail_heap_sIjtx):
  {
    Eterm targ1;
    GetR(0, targ1);
    {
      num_bits_term = targ1;
      alloc = I[2];
    }
  }
  I += 1;
  goto bs_init_bits__verify;

  OpCase(i_bs_init_bits_fail_xjtx):
  {
    num_bits_term = xb(I[1]);
    alloc = 0;
  }
  goto bs_init_bits__verify;

  OpCase(i_bs_init_bits_fail_yjtx):
  {
    num_bits_term = yb(I[1]);
    alloc = 0;
  }
  goto bs_init_bits__verify;

  OpCase(i_bs_init_bits_heap_WItx):
  {
    num_bits = I[1];
    alloc = I[2];
  }
  I += 1;
  goto bs_init_bits__execute;

  bs_init_bits__verify:
  {
    if (is_small(num_bits_term)) {
      Sint size = signed_val(num_bits_term);
      if (size < 0) {
        c_p->freason = BADARG;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[2])) {
          ASSERT(VALID_INSTR(*(I + (I[2]) + 1)));
          I += I[2] + 1;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      num_bits = (Uint) size;
    } else {
      Uint bits;

      if (!term_to_Uint(num_bits_term, &bits)) {
        c_p->freason = bits;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[2])) {
          ASSERT(VALID_INSTR(*(I + (I[2]) + 1)));
          I += I[2] + 1;;
          Goto(*I);;
        }
        goto find_func_info;;
      }
      num_bits = (Uint) bits;
    }
  }
  I += 1;
  goto bs_init_bits__execute;

  bs_init_bits__execute:
  {
    Eterm tmp_packed1 = I[2];
    BeamInstr next_pf = BeamCodeAddr(I[3]);
    Eterm new_binary;
    Uint num_bytes = ((Uint64)num_bits+(Uint64)7) >> 3;

    if (num_bits & 7) {
      alloc += ERL_SUB_BIN_SIZE;
    }
    if (num_bytes <= ERL_ONHEAP_BIN_LIMIT) {
      alloc += heap_bin_size(num_bytes);
    } else {
      alloc += PROC_BIN_SIZE;
    }
    do {
      Uint need = alloc + 0;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        SWAPOUT;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK), FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(alloc);
    } while (0);;

    /* num_bits = Number of bits to build
    * num_bytes = Number of bytes to allocate in the binary
    * alloc = Total number of words to allocate on heap
    * Operands: NotUsed NotUsed Dst
    */
    if (num_bytes <= ERL_ONHEAP_BIN_LIMIT) {
      ErlHeapBin* hb;

      erts_bin_offset = 0;
      erts_writable_bin = 0;
      hb = (ErlHeapBin *) HTOP;
      HTOP += heap_bin_size(num_bytes);
      hb->thing_word = header_heap_bin(num_bytes);
      hb->size = num_bytes;
      erts_current_bin = (byte *) hb->data;
      new_binary = make_binary(hb);

      do_bits_sub_bin:
      if (num_bits & 7) {
        ErlSubBin* sb;

        sb = (ErlSubBin *) HTOP;
        HTOP += ERL_SUB_BIN_SIZE;
        sb->thing_word = HEADER_SUB_BIN;
        sb->size = num_bytes - 1;
        sb->bitsize = num_bits & 7;
        sb->offs = 0;
        sb->bitoffs = 0;
        sb->is_writable = 0;
        sb->orig = new_binary;
        new_binary = make_binary(sb);
      }
      HEAP_SPACE_VERIFIED(0);
      xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = new_binary;
    } else {
      Binary* bptr;
      ProcBin* pb;

      erts_bin_offset = 0;
      erts_writable_bin = 0;

      /*
      * Allocate the binary struct itself.
      */
      bptr = erts_bin_nrml_alloc(num_bytes);
      erts_current_bin = (byte *) bptr->orig_bytes;

      /*
      * Now allocate the ProcBin on the heap.
      */
      pb = (ProcBin *) HTOP;
      HTOP += PROC_BIN_SIZE;
      pb->thing_word = HEADER_PROC_BIN;
      pb->size = num_bytes;
      pb->next = MSO(c_p).first;
      MSO(c_p).first = (struct erl_off_heap_header*) pb;
      pb->val = bptr;
      pb->bytes = (byte*) bptr->orig_bytes;
      pb->flags = 0;
      OH_OVERHEAD(&(MSO(c_p)), pb->size / sizeof(Eterm));
      new_binary = make_binary(pb);
      goto do_bits_sub_bin;
    }
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

OpCase(i_bs_match_string_xfWW):
{
  Eterm tmp_packed1 = I[1];
  byte* bytes = (byte *) I[3];
  Uint bits = I[2];
  ErlBinMatchBuffer* mb;
  Uint offs;

  mb = ms_matchbuffer(xb(tmp_packed1&BEAM_WIDE_MASK));
  if (mb->size - mb->offset < bits) {
    ASSERT(VALID_INSTR(*(I + (fb((tmp_packed1>>BEAM_WIDE_SHIFT))) + 0)));
    I += fb((tmp_packed1>>BEAM_WIDE_SHIFT)) + 0;;
    Goto(*I);;
  }
  offs = mb->offset & 7;
  if (offs == 0 && (bits & 7) == 0) {
    if (sys_memcmp(bytes, mb->base+(mb->offset>>3), bits>>3)) {
      ASSERT(VALID_INSTR(*(I + (fb((tmp_packed1>>BEAM_WIDE_SHIFT))) + 0)));
      I += fb((tmp_packed1>>BEAM_WIDE_SHIFT)) + 0;;
      Goto(*I);;
    }
  } else if (erts_cmp_bits(bytes, 0, mb->base+(mb->offset>>3), mb->offset & 7, bits)) {
    ASSERT(VALID_INSTR(*(I + (fb((tmp_packed1>>BEAM_WIDE_SHIFT))) + 0)));
    I += fb((tmp_packed1>>BEAM_WIDE_SHIFT)) + 0;;
    Goto(*I);;
  }
  mb->offset += bits;
  I += 4;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_private_append_jtsSx):
{
  Eterm tmp_packed1 = I[2];
  Eterm targ1;
  GetR(2, targ1);
  {
    Eterm res;

    res = erts_bs_private_append(c_p, Sb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK), targ1, tb(tmp_packed1&BEAM_TIGHT_MASK));
    if (is_non_value(res)) {
      /* c_p->freason is already set (to BADARG or SYSTEM_LIMIT). */

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(I[1])) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      goto find_func_info;;
    }
    xb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = res;
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_put_utf8_js):
{
  Eterm targ1;
  GetR(1, targ1);
  {
    if (!erts_bs_put_utf8(ERL_BITS_ARGS_1(targ1))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(I[1])) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_restore2_xt):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ErlBinMatchState* _ms = (ErlBinMatchState*) boxed_val((Eterm) xb(tmp_packed1&BEAM_LOOSE_MASK));
  _ms->mb.offset = _ms->save_offset[tb((tmp_packed1>>BEAM_LOOSE_SHIFT))];
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_save2_xt):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ErlBinMatchState* _ms = (ErlBinMatchState*) boxed_val((Eterm) xb(tmp_packed1&BEAM_LOOSE_MASK));
  _ms->save_offset[tb((tmp_packed1>>BEAM_LOOSE_SHIFT))] = _ms->mb.offset;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_skip_bits2_fxxt):
{
  Eterm tmp_packed1 = I[2];
  ErlBinMatchBuffer *_mb;
  size_t new_offset;
  Uint _size;

  _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_TIGHT_MASK));
  do {
    Sint signed_size;
    Uint uint_size;
    Uint temp_bits;

    if (is_small(xb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK))) {
      signed_size = signed_val(xb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK));
      if (signed_size < 0) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      uint_size = (Uint) signed_size;
    } else {
      if (!term_to_Uint(xb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK), &temp_bits)) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      uint_size = temp_bits;
    }
    do {
      Uint64 res = (uint_size) * (tb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))));
      if (res / tb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) != uint_size) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      _size = res;
    } while (0);
  } while (0);
  new_offset = _mb->offset + _size;
  if (new_offset <= _mb->size) {
    _mb->offset = new_offset;
  } else {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_skip_bits2_fxyt):
{
  Eterm tmp_packed1 = I[2];
  ErlBinMatchBuffer *_mb;
  size_t new_offset;
  Uint _size;

  _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_TIGHT_MASK));
  do {
    Sint signed_size;
    Uint uint_size;
    Uint temp_bits;

    if (is_small(yb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK))) {
      signed_size = signed_val(yb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK));
      if (signed_size < 0) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      uint_size = (Uint) signed_size;
    } else {
      if (!term_to_Uint(yb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK), &temp_bits)) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      uint_size = temp_bits;
    }
    do {
      Uint64 res = (uint_size) * (tb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))));
      if (res / tb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) != uint_size) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      _size = res;
    } while (0);
  } while (0);
  new_offset = _mb->offset + _size;
  if (new_offset <= _mb->size) {
    _mb->offset = new_offset;
  } else {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_skip_bits_all2_fxt):
{
  Eterm tmp_packed1 = I[2];
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb(tmp_packed1&BEAM_LOOSE_MASK));
  if (((_mb->size - _mb->offset) % tb((tmp_packed1>>BEAM_LOOSE_SHIFT))) == 0) {
    _mb->offset = _mb->size;
  } else {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_skip_bits_imm2_fxW):
{
  Eterm tmp_packed1 = I[1];
  ErlBinMatchBuffer *_mb;
  size_t new_offset;
  _mb = ms_matchbuffer(xb((tmp_packed1>>BEAM_WIDE_SHIFT)));
  new_offset = _mb->offset + (I[2]);
  if (new_offset <= _mb->size) {
    _mb->offset = new_offset;
  } else {
    ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
    I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

{
  Eterm context;
  OpCase(i_bs_start_match2_xfttx):
  {
    context = xb(I[1]);
  }
  goto bs_start_match__execute;

  OpCase(i_bs_start_match2_yfttx):
  {
    context = yb(I[1]);
  }
  goto bs_start_match__execute;

  bs_start_match__execute:
  {
    Eterm tmp_packed1 = I[3];
    Uint slots;
    Uint live;
    Eterm header;
    if (!is_boxed(context)) {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }
    header = *boxed_val(context);
    slots = tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
    live = tb(tmp_packed1&BEAM_TIGHT_MASK);
    if (header_is_bin_matchstate(header)) {
      ErlBinMatchState* ms = (ErlBinMatchState *) boxed_val(context);
      Uint actual_slots = HEADER_NUM_SLOTS(header);
      ms->save_offset[0] = ms->mb.offset;
      if (actual_slots < slots) {
        ErlBinMatchState* dst;
        Uint live = tb(tmp_packed1&BEAM_TIGHT_MASK);
        Uint wordsneeded = ERL_BIN_MATCHSTATE_SIZE(slots);

        do {
          Uint need = wordsneeded;
          if (ERTS_UNLIKELY(E - HTOP < need)) {
            SWAPOUT;
            reg[live] = context;
            PROCESS_MAIN_CHK_LOCKS(c_p);
            FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, live+1, FCALLS);
            ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
            PROCESS_MAIN_CHK_LOCKS(c_p);
            context = reg[live];
            SWAPIN;
          }
          HEAP_SPACE_VERIFIED(wordsneeded);
        } while (0);
        ms = (ErlBinMatchState *) boxed_val(context);
        dst = (ErlBinMatchState *) HTOP;
        *dst = *ms;
        *HTOP = HEADER_BIN_MATCHSTATE(slots);
        HTOP += wordsneeded;
        HEAP_SPACE_VERIFIED(0);
        xb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = make_matchstate(dst);
      }
    } else if (is_binary_header(header)) {
      Eterm result;
      Uint wordsneeded = ERL_BIN_MATCHSTATE_SIZE(slots);
      do {
        Uint need = wordsneeded;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          SWAPOUT;
          reg[live] = context;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, live+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          context = reg[live];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(wordsneeded);
      } while (0);
      HEAP_TOP(c_p) = HTOP;
#ifdef DEBUG
      c_p->stop = E;	/* Needed for checking in HeapOnlyAlloc(). */
#endif
      result = erts_bs_start_match_2(c_p, context, slots);
      HTOP = HEAP_TOP(c_p);
      HEAP_SPACE_VERIFIED(0);
      if (is_non_value(result)) {
        ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
        I += I[2] + 0;;
        Goto(*I);;
      }
      xb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = result;
    } else {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_bs_utf16_size_sx):
{
  Eterm targ1;
  BeamInstr next_pf = BeamCodeAddr(I[3]);
  GetR(0, targ1);
  {
    Eterm arg = targ1;
    Eterm result = make_small(2);

    /*
    * Calculate the number of bytes needed to encode the source
    * operarand to UTF-16. If the source operand is invalid (e.g. wrong
    * type or range) we return a nonsense integer result (2 or 4). We
    * can get away with that because we KNOW that bs_put_utf16 will do
    * full error checking.
    */

    if (arg >= make_small(0x10000UL)) {
      result = make_small(4);
    }
    xb(I[2]) = result;
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }
}

OpCase(i_bs_utf8_size_sx):
{
  Eterm targ1;
  BeamInstr next_pf = BeamCodeAddr(I[3]);
  GetR(0, targ1);
  {
    Eterm arg = targ1;
    Eterm result;

    /*
    * Calculate the number of bytes needed to encode the source
    * operand to UTF-8. If the source operand is invalid (e.g. wrong
    * type or range) we return a nonsense integer result (0 or 4). We
    * can get away with that because we KNOW that bs_put_utf8 will do
    * full error checking.
    */

    if (arg < make_small(0x80UL)) {
      result = make_small(1);
    } else if (arg < make_small(0x800UL)) {
      result = make_small(2);
    } else if (arg < make_small(0x10000UL)) {
      result = make_small(3);
    } else {
      result = make_small(4);
    }
    xb(I[2]) = result;
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }
}

OpCase(i_bs_validate_unicode_js):
{
  Eterm targ1;
  GetR(1, targ1);
  {
    Eterm val = targ1;

    /*
    * There is no need to untag the integer, but it IS necessary
    * to make sure it is small (if the term is a bignum, it could
    * slip through the test, and there is no further test that
    * would catch it, since bit syntax construction silently masks
    * too big numbers).
    */
    if (is_not_small(val) || val > make_small(0x10FFFFUL) ||
    (make_small(0xD800UL) <= val && val <= make_small(0xDFFFUL))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(I[1])) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_validate_unicode_retract_jsS):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  GetR(1, targ1);
  {
    /*
    * There is no need to untag the integer, but it IS necessary
    * to make sure it is small (a bignum pointer could fall in
    * the valid range).
    */

    Eterm i = targ1;
    if (is_not_small(i) || i > make_small(0x10FFFFUL) ||
    (make_small(0xD800UL) <= i && i <= make_small(0xDFFFUL))) {
      Eterm ms = Sb((tmp_packed1>>BEAM_WIDE_SHIFT));		/* Match context */
      ErlBinMatchBuffer* mb;

      /* Invalid value. Retract the position in the binary. */
      mb = ms_matchbuffer(ms);
      mb->offset -= 32;
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_fadd_lll):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = lb(tmp_packed1&BEAM_TIGHT_MASK) + lb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
  ERTS_NO_FPE_ERROR(c_p, lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fdiv_lll):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = lb(tmp_packed1&BEAM_TIGHT_MASK) / lb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
  ERTS_NO_FPE_ERROR(c_p, lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fmul_lll):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = lb(tmp_packed1&BEAM_TIGHT_MASK) * lb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
  ERTS_NO_FPE_ERROR(c_p, lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fnegate_ll):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  lb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = -lb(tmp_packed1&BEAM_LOOSE_MASK);
  ERTS_NO_FPE_ERROR(c_p, lb((tmp_packed1>>BEAM_LOOSE_SHIFT)), c_p->freason = BADARITH;
  goto find_func_info;);
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fsub_lll):
{
  Eterm tmp_packed1 = I[1];
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = lb(tmp_packed1&BEAM_TIGHT_MASK) - lb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
  ERTS_NO_FPE_ERROR(c_p, lb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_new_bs_put_binary_all_jst):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  GetR(1, targ1);
  {
    if (!erts_new_bs_put_binary_all(ERL_BITS_ARGS_2((targ1), (tb((tmp_packed1>>BEAM_WIDE_SHIFT)))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_binary_imm_jWs):
{
  Eterm targ1;
  GetR(2, targ1);
  {
    if (!erts_new_bs_put_binary(ERL_BITS_ARGS_2((targ1), (I[2])))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(I[1])) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_binary_jsts):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  Eterm targ2;
  GetR(1, targ1);
  GetR(2, targ2);
  {
    Sint _size;
    do {
      Sint signed_size;
      Uint uint_size;
      Uint temp_bits;

      if (is_small(targ1)) {
        signed_size = signed_val(targ1);
        if (signed_size < 0) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
            ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
            I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        uint_size = (Uint) signed_size;
      } else {
        if (!term_to_Uint(targ1, &temp_bits)) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
            ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
            I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        uint_size = temp_bits;
      }
      _size = uint_size * ((tb((tmp_packed1>>BEAM_WIDE_SHIFT))) >> 3);
    } while (0);
    if (!erts_new_bs_put_binary(ERL_BITS_ARGS_2((targ2), _size))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_float_imm_jWts):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  GetR(2, targ1);
  {
    if (!erts_new_bs_put_float(c_p, (targ1), (I[2]), (tb((tmp_packed1>>BEAM_WIDE_SHIFT))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_float_jsts):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  Eterm targ2;
  GetR(1, targ1);
  GetR(2, targ2);
  {
    Sint _size;
    do {
      Sint signed_size;
      Uint uint_size;
      Uint temp_bits;

      if (is_small(targ1)) {
        signed_size = signed_val(targ1);
        if (signed_size < 0) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
            ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
            I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        uint_size = (Uint) signed_size;
      } else {
        if (!term_to_Uint(targ1, &temp_bits)) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
            ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
            I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        uint_size = temp_bits;
      }
      _size = uint_size * ((tb((tmp_packed1>>BEAM_WIDE_SHIFT))) >> 3);
    } while (0);
    if (!erts_new_bs_put_float(c_p, (targ2), _size, (tb((tmp_packed1>>BEAM_WIDE_SHIFT))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_integer_imm_jWts):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  GetR(2, targ1);
  {
    if (!erts_new_bs_put_integer(ERL_BITS_ARGS_3((targ1), (I[2]), (tb((tmp_packed1>>BEAM_WIDE_SHIFT)))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_integer_jsts):
{
  Eterm tmp_packed1 = I[1];
  Eterm targ1;
  Eterm targ2;
  GetR(1, targ1);
  GetR(2, targ2);
  {
    Sint _size;
    do {
      Sint signed_size;
      Uint uint_size;
      Uint temp_bits;

      if (is_small(targ1)) {
        signed_size = signed_val(targ1);
        if (signed_size < 0) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
            ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
            I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        uint_size = (Uint) signed_size;
      } else {
        if (!term_to_Uint(targ1, &temp_bits)) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
            ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
            I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        uint_size = temp_bits;
      }
      _size = uint_size * ((tb((tmp_packed1>>BEAM_WIDE_SHIFT))) >> 3);
    } while (0);
    if (!erts_new_bs_put_integer(ERL_BITS_ARGS_3((targ2), _size, (tb((tmp_packed1>>BEAM_WIDE_SHIFT)))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

